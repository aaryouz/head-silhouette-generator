# -*- coding: utf-8 -*-
"""Untitled66.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AaEpKieKeNOaJ3iuieIN9-CdVHmscxzE
"""

# =======================
# Head Silhouette Generator (Colab)
# =======================
# - Upload a face image when prompted
# - Produces: silhouette.png (full-size), weights.png (128x128), and debug overlays
# -----------------------

!pip -q install mediapipe==0.10.14

import io, os, math
import numpy as np
import cv2
from google.colab import files
from google.colab.patches import cv2_imshow
import mediapipe as mp

# ---------- Tunables ----------
SEG_THRESHOLD   = 0.55   # confidence threshold for person mask
MARGIN_X        = 0.18   # expand ROI horizontally (fraction of face width)
MARGIN_Y_TOP    = 0.30   # expand ROI upward
MARGIN_Y_BOTTOM = 0.22   # expand ROI downward to include a bit of neck
NECK_FRACTION   = 0.10   # keep this fraction of face-height below chin as 'neck'
SMOOTH_RADIUS   = 11     # morphological smoothing (odd number)
BLUR_KSIZE      = 9      # final blur before hard threshold (odd number)
OUT_SIZE        = 128    # weights.png size

# ---------- Upload ----------
print("Upload a face image (png/jpg)…")
up = files.upload()
if not up:
    raise SystemExit("No file uploaded.")

fname = list(up.keys())[0]
data = up[fname]
img = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
if img is None:
    raise SystemExit("Could not read the image.")

h, w = img.shape[:2]
rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# ---------- MediaPipe models ----------
mp_face_mesh = mp.solutions.face_mesh
mp_selfie    = mp.solutions.selfie_segmentation

# Selfie segmentation (person mask)
with mp_selfie.SelfieSegmentation(model_selection=1) as selfie:
    seg = selfie.process(rgb).segmentation_mask
    person_mask = (seg > SEG_THRESHOLD).astype(np.uint8)  # 0/1

# Face landmarks (for precise head bbox + chin)
face_bbox = None
chin_y = None
with mp_face_mesh.FaceMesh(static_image_mode=True,
                           refine_landmarks=True,
                           max_num_faces=1) as fm:
    res = fm.process(rgb)
    if res.multi_face_landmarks:
        lms = res.multi_face_landmarks[0].landmark

        # Face oval indices from mediapipe (468-landmark topology):
        # Using the published FACEMESH_FACE_OVAL set
        FACEMESH_FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454,
                              323, 361, 288, 397, 365, 379, 378, 400, 377,
                              152, 148, 176, 149, 150, 136, 172, 58, 132,
                              93, 234, 127, 162, 21, 54, 103, 67, 109]

        xs, ys = [], []
        for idx in FACEMESH_FACE_OVAL:
            xs.append(lms[idx].x * w)
            ys.append(lms[idx].y * h)
        xs = np.array(xs); ys = np.array(ys)

        x_min, x_max = xs.min(), xs.max()
        y_min, y_max = ys.min(), ys.max()
        face_w = x_max - x_min
        face_h = y_max - y_min

        # Expand the rectangle to include ears + a bit of neck & top
        rx0 = int(max(0, x_min - MARGIN_X * face_w))
        rx1 = int(min(w, x_max + MARGIN_X * face_w))
        ry0 = int(max(0, y_min - MARGIN_Y_TOP * face_h))
        ry1 = int(min(h, y_max + MARGIN_Y_BOTTOM * face_h))
        face_bbox = (rx0, ry0, rx1, ry1)

        # Chin landmark (152 is 'chin' in the mesh)
        chin_y = int(lms[152].y * h)

# ---------- Build a head-only mask ----------
# Start from person mask, then keep the connected component intersecting the face ROI.
binary = (person_mask * 255).astype(np.uint8)

if face_bbox is None:
    # Fallback: take largest connected component in person mask (assume it's the person)
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity=8)
    if num_labels <= 1:
        head_mask = np.zeros_like(binary)
    else:
        largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
        head_mask = (labels == largest).astype(np.uint8) * 255
else:
    rx0, ry0, rx1, ry1 = face_bbox
    roi = binary[ry0:ry1, rx0:rx1].copy()

    # Find connected components in ROI; keep the largest that overlaps the center of ROI
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(roi, connectivity=8)
    head_roi = np.zeros_like(roi)
    if num_labels > 1:
        # choose the comp with max overlap with a small box around face center
        cx, cy = (rx1 - rx0) // 2, (ry1 - ry0) // 2
        best_label, best_score = 0, -1
        for label in range(1, num_labels):
            comp = (labels == label).astype(np.uint8)
            score = comp[ max(0,cy-10):min(roi.shape[0],cy+10),
                          max(0,cx-10):min(roi.shape[1],cx+10) ].sum()
            area  = stats[label, cv2.CC_STAT_AREA]
            score = score + 0.001 * area  # tiebreak by area
            if score > best_score:
                best_score = score
                best_label = label
        head_roi[labels == best_label] = 255

    # Paste ROI back to full-size mask
    head_mask = np.zeros_like(binary)
    head_mask[ry0:ry1, rx0:rx1] = head_roi

    # Cut off shoulders: remove mask far below chin, but keep a small neck
    if chin_y is not None:
        if face_bbox is not None:
            face_h_est = (ry1 - ry0)
            neck_cut = int(min(h-1, chin_y + NECK_FRACTION * face_h_est))
            head_mask[neck_cut:, :] = 0

# ---------- Smooth / clean mask ----------
if SMOOTH_RADIUS % 2 == 0: SMOOTH_RADIUS += 1
if BLUR_KSIZE % 2 == 0: BLUR_KSIZE += 1

kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (SMOOTH_RADIUS, SMOOTH_RADIUS))
clean = cv2.morphologyEx(head_mask, cv2.MORPH_CLOSE, kernel, iterations=1)
clean = cv2.morphologyEx(clean, cv2.MORPH_OPEN,  kernel, iterations=1)
clean = cv2.GaussianBlur(clean, (BLUR_KSIZE, BLUR_KSIZE), 0)

# Hard threshold to crisp black/white
_, silhouette = cv2.threshold(clean, 127, 255, cv2.THRESH_BINARY)

# Ensure single connected component around the face (optional safety)
num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(silhouette, connectivity=8)
if num_labels > 1:
    # keep largest
    largest = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])
    silhouette = ((labels == largest).astype(np.uint8) * 255)

# ---------- Create white-on-black result ----------
silhouette_rgb = cv2.cvtColor(silhouette, cv2.COLOR_GRAY2BGR)  # white head, black bg

# Save full-size
full_out = "silhouette.png"
cv2.imwrite(full_out, silhouette)

# Also save a centered 128×128 version named weights.png (useful for pipelines)
ys, xs = np.where(silhouette > 0)
if len(xs) and len(ys):
    x0, x1 = xs.min(), xs.max()
    y0, y1 = ys.min(), ys.max()
    pad = int(0.08 * max(x1 - x0, y1 - y0))
    x0 = max(0, x0 - pad); y0 = max(0, y0 - pad)
    x1 = min(w, x1 + pad); y1 = min(h, y1 + pad)
    crop = silhouette[y0:y1, x0:x1]
    # make square canvas
    side = max(crop.shape[:2])
    canvas = np.zeros((side, side), np.uint8)
    y_off = (side - crop.shape[0]) // 2
    x_off = (side - crop.shape[1]) // 2
    canvas[y_off:y_off+crop.shape[0], x_off:x_off+crop.shape[1]] = crop
    weights = cv2.resize(canvas, (OUT_SIZE, OUT_SIZE), interpolation=cv2.INTER_AREA)
else:
    weights = cv2.resize(silhouette, (OUT_SIZE, OUT_SIZE), interpolation=cv2.INTER_AREA)

cv2.imwrite("weights.png", weights)

# ---------- Debug overlays ----------
overlay = img.copy()
overlay[silhouette > 0] = (255, 255, 255)  # paint head region white
debug = cv2.addWeighted(img, 0.6, overlay, 0.4, 0)

# ---------- Show results ----------
print("Preview: original, silhouette, 128×128 weights, and debug overlay.")
cv2_imshow(img)
cv2_imshow(silhouette_rgb)
cv2_imshow(cv2.cvtColor(cv2.resize(weights, (256,256), interpolation=cv2.INTER_NEAREST), cv2.COLOR_GRAY2BGR))
cv2_imshow(debug)

print("\nSaved files:")
for p in [full_out, "weights.png"]:
    print("-", p)